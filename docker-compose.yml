services:
  postgres:
    image: postgres:16
    container_name: shai-postgres
    environment:
      - POSTGRES_DB=mlengine
      - POSTGRES_USER=ml
      - POSTGRES_PASSWORD=ml
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ml -d mlengine"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - shai-network
    restart: unless-stopped

  parser:
    build: ./services/parser
    container_name: shai-parser
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - OUT_FILE=/app/data/normalized.jsonl
    volumes:
      - parser-data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - shai-network
    restart: unless-stopped

  shipper:
    build: ./services/parser
    container_name: shai-shipper
    command: ["python3", "shipper.py", "--file", "/app/data/normalized.jsonl", "--ml", "http://ml-detector:8000/score", "--batch", "200", "--flush-interval", "0.5"]
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      - parser-data:/app/data
    depends_on:
      parser:
        condition: service_healthy
      ml-detector:
        condition: service_healthy
    networks:
      - shai-network
    restart: unless-stopped

  ml-detector:
    build: ./services/ml-detector
    container_name: shai-ml-detector
    ports:
      - "8001:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - MODEL_PATH=/app/data/isoforest_perip.joblib
      - ACTIONS_PATH=/app/data/actions.jsonl
      - PG_DSN=postgresql://ml:ml@postgres:5432/mlengine
      # Настройки для очистки каждые 2 минуты
      - WINDOW_MINUTES=60
      - MIN_TRAIN_ROWS=50
      - RETRAIN_EVERY=2
      - CLEANUP_OLD_DATA=1
      - MAX_FEATURES_AGE_HOURS=24
    volumes:
      - ml-data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - shai-network
    restart: unless-stopped

  # Auth log generator (SSH logs)
  auth-generator:
    build: ./services/log-generator
    container_name: shai-auth-generator
    command: ["python3", "generator_auth.py", "--scenario", "normal", "--rate", "10", "--loop"]
    environment:
      - INGEST_URL=http://parser:8000/ingest
      - PYTHONUNBUFFERED=1
    depends_on:
      parser:
        condition: service_healthy
    networks:
      - shai-network
    restart: unless-stopped

  # Firewall log generator
  fw-generator:
    build: ./services/log-generator
    container_name: shai-fw-generator
    command: ["python3", "generator_fw.py", "--scenario", "normal", "--realtime"]
    environment:
      - INGEST_URL=http://parser:8000/ingest
      - PYTHONUNBUFFERED=1
    depends_on:
      parser:
        condition: service_healthy
    networks:
      - shai-network
    restart: unless-stopped

  # Application log generator
  app-generator:
    build: ./services/log-generator
    container_name: shai-app-generator
    command: ["python3", "generator_app.py", "--scenario", "normal", "--rate", "5", "--loop"]
    environment:
      - INGEST_URL=http://parser:8000/ingest
      - PYTHONUNBUFFERED=1
    depends_on:
      parser:
        condition: service_healthy
    networks:
      - shai-network
    restart: unless-stopped

networks:
  shai-network:
    driver: bridge

volumes:
  parser-data:
    driver: local
  ml-data:
    driver: local
  postgres-data:
    driver: local
